id: 69010
name: GPT-4o   名称:GPT-4o
icon_uri: default_icon/openai_v2.png
icon_url: ""
description:
    zh: gpt 模型简介
    en: Multi-modal, 320ms, 88.7% MMLU, excels in education, customer support, health, and entertainment.
default_parameters:
    - name: temperature
      label:
        zh: 生成随机性
        en: Temperature
      desc:
        zh: '- **temperature**: 调高温度会使得模型的输出更多样性和创新性，反之，降低温度会使输出内容更加遵循指令要求但减少多样性。建议不要与“Top p”同时调整。'
        en: '**Temperature**:\n\n- When you increase this value, the model outputs more diverse and innovative content; when you decrease it, the model outputs less diverse content that strictly follows the given instructions.\n- It is recommended not to adjust this value with \"Top p\" at the same time.'
      type: float
      min: "0"
      max: "1"
      default_val:
        balance: "0.8"
        creative: "1"
        default_val: "1.0"
        precise: "0.3"
      precision: 1
      options: []
      style:
        widget: slider
        label:
            zh: 生成多样性
            en: Generation diversity
    - name: max_tokens
      label:
        zh: 最大回复长度
        en: Response max length
      desc:
        zh: 控制模型输出的Tokens 长度上限。通常 100 Tokens 约等于 150 个中文汉字。
        en: You can specify the maximum length of the tokens output through this value. Typically, 100 tokens are approximately equal to 150 Chinese characters.
      type: int
      min: "1"
      max: "4096"
      default_val:
        default_val: "4096"
      options: []
      style:
        widget: slider
        label:
            zh: 输入及输出设置
            en: Input and output settings
    - name: top_p
      label:
        zh: Top P
        en: Top P
      desc:
        zh: '- **Top p 为累计概率**: 模型在生成输出时会从概率最高的词汇开始选择，直到这些词汇的总概率累积达到Top p 值。这样可以限制模型只选择这些高概率的词汇，从而控制输出内容的多样性。建议不要与“生成随机性”同时调整。'
        en: '**Top P**:\n\n- An alternative to sampling with temperature, where only tokens within the top p probability mass are considered. For example, 0.1 means only the top 10% probability mass tokens are considered.\n- We recommend altering this or temperature, but not both.'
      type: float
      min: "0"
      max: "1"
      default_val:
        default_val: "0.7"
      precision: 2
      options: []
      style:
        widget: slider
        label:   标签:
            zh: 生成多样性
            en: Generation diversity
    - name: frequency_penalty
      label:
        zh: 重复语句惩罚
        en: Frequency penalty
      desc:
        zh: '- **frequency penalty**: 当该值为正时，会阻止模型频繁使用相同的词汇和短语，从而增加输出内容的多样性。'
        en: '**Frequency Penalty**: When positive, it discourages the model from repeating the same words and phrases, thereby increasing the diversity of the output.'
      type: float
      min: "-2"
      max: "2"
      default_val:
        default_val: "0"
      precision: 2
      options: []
      style:   风格:
        widget: slider
        label:   标签:
            zh: 生成多样性
            en: Generation diversity   en：世代多样性
    - name: presence_penalty
      label:
        zh: 重复主题惩罚
        en: Presence penalty
      desc:   描述:
        zh: '- **presence penalty**: 当该值为正时，会阻止模型频繁讨论相同的主题，从而增加输出内容的多样性'
        en: '**Presence Penalty**: When positive, it prevents the model from discussing the same topics repeatedly, thereby increasing the diversity of the output.'en：“**存在惩罚**：当为正值时，它可以防止模型重复讨论相同的主题，从而增加输出的多样性。”
      type: float   类型:浮动
      min: "-2"   分钟:“2”
      max: "2"   马克斯:“2”
      default_val:
        default_val: "0"
      precision: 2   精度:2
      options: []   选择:[]
      style:   风格:
        widget: slider   部件:滑块
        label:   标签:
            zh: 生成多样性
            en: Generation diversity   en：世代多样性
    - name: response_format   —name: response_format
      label:   标签:
        zh: 输出格式
        en: Response format   en：回应格式
      desc:   描述:
        zh: '- **文本**: 使用普通文本格式回复\n- **Markdown**: 将引导模型使用Markdown格式输出回复\n- **JSON**: 将引导模型使用JSON格式输出'
        en: '**Response Format**:\n\n- **Text**: Replies in plain text format\n- **Markdown**: Uses Markdown format for replies\n- **JSON**: Uses JSON format for replies'en: ‘**响应格式**:\n\n- **文本**：以纯文本格式回复\n- **Markdown**：使用Markdown格式回复\n- **JSON**：使用JSON格式回复’
      type: int   类型:int
      min: ""   分钟:”“
      max: ""   马克斯:“
      default_val:
        default_val: "0"
      options   选项:
        - label: Text
          value: "0"
        - label: Markdown   部件:滑块
          value: "1"
        - label: JSON
          value: "2"en：输入输出设置
      style   风格:   风格:   —名称：top_p
        widget   小部件: radio_buttons
        label   标签:   标签:
            zh   古银: 输入及输出设置
            en   在: Input and output settingsen：输入输出设置
meta   元:
    protocol   协议: openai
    capability:zh：多模式，320ms, 88.7% MMLU，擅长教育、客户支持、健康和娱乐。   类型:浮动
        function_call: true   真正的
        input_modal:   -名称：温度
            - text   ——文本
            - image   ——图片
        input_tokens: 128000   en:温度
        json_mode: false   假Json_mode: false   假
        max_tokens: 128000
        output_modal:   部件:滑块
            - text   类型:浮动
        output_tokens: 16384
        prefix_caching: false   en：世代多样性
        reasoning   推理: false   —name:    假frequency_penalty
        prefill_response: false   假preill_response: false   假
    conn_config:
        base_url: "https://api.openai.com/v1"   en：频率惩罚
        api_key: ""
        timeout   超时: 0s
        model   模型: ""
        temperature   温度: 0.7   类型:浮动
        frequency_penalty: 0   部件:滑块
        presence_penalty: 0
        max_tokens: 4096
        top_p: 1   en：世代多样性
        top_k: 0   —name: max_tokens
        stop   停止: []
        openai:
            by_azure: false   en：最大响应长度   部件:滑块
            api_version: ""
            response_format:
                type   类型: texten：您可以通过此值指定输出令牌的最大长度。一般来说，100个记号大约等于150个汉字。   en：世代多样性
                jsonschema: null   —name: presence_penalty
        custom   自定义: {}
    status   状态: 0
