/*
 * Copyright 2025 coze-dev Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
 
// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.
/* eslint-disable */
/* tslint:disable */
// @ts-nocheck

import * as flow_devops_evaluation_task from './flow_devops_evaluation_task';
import * as flow_devops_evaluation_evaluator from './flow_devops_evaluation_evaluator';
import * as model from './model';
import * as flow_devops_evaluation_dataset from './flow_devops_evaluation_dataset';

export type Int64 = string | number;

export enum DatasetPreHandlerType {
  None = 0,
  PromptTemplate = 1,
}

export enum InputPreHandlerType {
  None = 0,
  URL = 1,
}

export enum MerlinSeedModelType {
  Unknown = 0,
  Hdfs = 1,
}

export enum OfflineEvalTaskModelSource {
  Unknown = 0,
  MerlinSeed = 1,
  FornaxSftTask = 2,
  /** pedestal model */
  FoundationModel = 3,
}

export enum OfflineEvalTaskStatus {
  Preparing = 0,
  Launching = 1,
  Inferring = 2,
  Evaluating = 3,
  Success = 4,
  Failed = 5,
  Terminating = 6,
  Terminated = 7,
  PartialFailed = 8,
}

export interface InferResExportStatus {
  /** The HDFS address of the resulting file */
  hdfsPath?: string;
  /** Export progress of the current file */
  cursor?: string;
  /** Whether the export is complete */
  isExported?: boolean;
}

export interface OfflineEvalProduction {
  datasetID?: string;
  resultSetID?: string;
  caseTaskID?: string;
  /** Every time you read, you need rpc to get the EvalCaseTask (both Get and List are required), and you should not write to the database when writing */
  evalCaseTask?: flow_devops_evaluation_task.Task;
  /** The ID of the last piece of data written */
  lastOutputCursor?: Int64;
}

export interface OfflineEvalTask {
  id?: string;
  name?: string;
  desc?: string;
  model?: OfflineEvalTaskModel;
  datasets?: Array<OfflineEvalTaskDataset>;
  /** Every time you read, you need rpc to get RuleGroup. Rules (only Get is required, List is not required) */
  evalRuleGroup?: flow_devops_evaluation_evaluator.RuleGroup;
  resource?: model.SftTaskResource;
  ckptConfig?: OfflineEvalTaskCkptConfig;
  status?: OfflineEvalTaskStatus;
  provider?: model.Provider;
  providerTaskID?: string;
  caseID?: string;
  ckptResult?: OfflineEvalTaskCkptResult;
  errCode?: string;
  errMessage?: string;
  displayErrMsg?: string;
  /** Has the rule group been deleted? */
  isRuleGroupDeleted?: boolean;
  /** Fornax space ID */
  spaceID?: string;
  /** creator ID */
  createdBy?: string;
  /** Creation time, seconds */
  createdAt?: string;
  /** Updater ID */
  updatedBy?: string;
  /** Update time in seconds */
  updatedAt?: string;
}

export interface OfflineEvalTaskCkptConfig {
  /** Key is name */
  items?: Record<string, OfflineEvalTaskCkptConfigItem>;
}

export interface OfflineEvalTaskCkptConfigItem {
  name?: string;
  def?: string;
  nextCkptName?: string;
  maxRetryTime?: string;
  retryIntervalMilliSecond?: string;
  /** The way the retry interval changes, supporting fixed intervals and gradual changes over time */
  retryIntervalChangeType?: string;
  /** For every x retries, the retry interval changes */
  retryIntervalChangeTimes?: string;
  /** The step size of each retry interval, in ms, can be negative */
  retryIntervalChangeStep?: string;
  customConfigs?: Record<string, string>;
  /** Time interval to trigger the next checkpoint in ms */
  triggerNextCkptIntervalMilliSecond?: string;
}

export interface OfflineEvalTaskCkptResult {
  /** Address where the review set is uploaded to hdfs */
  datasetHdfsAddress?: string;
  /** The hdfs address where the inference result is saved, possibly a folder (files rather than folders are required for open-source models). */
  inferResultHdfsAddress?: string;
  /** Inference result export progress */
  resultExportStatuses?: Array<InferResExportStatus>;
  /** Merlin inference task status */
  merlinDataProcessingInstanceStatusGroup?: string;
  /** Merlin inference task status details */
  merlinDataProcessingInstanceStatus?: string;
  /** Incoming data column names for offline inference tasks */
  inferTaskColumnName?: string;
  /** Offline evaluation products */
  evalProductions?: Array<OfflineEvalProduction>;
  /** Whether the result set export is complete */
  resultSetExported?: boolean;
  /** The merlin seed offline inference task is actually outsourced in the merlin task use case, record the merlin task use case id here */
  merlinJobID?: string;
  /** Merlin seed offline inference task link */
  merlinSeedTaskUrl?: string;
  /** Merlin task instance terminated */
  merlinJobTerminated?: boolean;
  /** Save raw information for types of data other than plainText */
  originDataColumnName?: string;
  /** The column name of the batch inference result, the old data may be empty, and the value is output when empty (column name in parquet. If it is jsonl, the format is ark fixed) */
  outputColumnName?: string;
  /** Column names of raw batch inference results (column names in parquet) */
  originOutputColumnName?: string;
  /** ID for batch inference tasks */
  batchInferTaskID?: Int64;
  /** The state of batch inference tasks */
  batchInferTaskStatus?: string;
  /** Batch inference One of the column names in the input data that records the unique ID of each row in the data */
  itemIDColumnName?: string;
  /** The bucket name of the review set uploaded to tos */
  datasetTosBucketName?: string;
  /** File path after the review set is uploaded to tos */
  datasetTosObjectKey?: string;
  /** The inference result is saved to the bucket name of tos */
  inferResultTosBucketName?: string;
  /** The folder path after the inference result is saved to tos */
  inferResultTosObjectKey?: string;
  /** Volcano project name, used to record the project name of the user-hosted ByteCloud Ark account */
  volcEngineProjectName?: string;
  /** Upload the pictures in the evaluation set to the address (folder) of hdfs. */
  datasetImageHdfsAddress?: string;
}

export interface OfflineEvalTaskDataset {
  evalDataset?: flow_devops_evaluation_dataset.DatasetInfo;
  /** Dataset preprocessing */
  datasetPreHandler?: OfflineEvalTaskDatasetPreHandler;
  /** model input preprocessing */
  inputPreHandler?: OfflineEvalTaskInputPreHandler;
  /** Has it been uploaded to HDFS? */
  uploaded?: boolean;
  /** Upload progress cursor */
  uploadCursor?: Int64;
  /** Has it been deleted? */
  isDeleted?: boolean;
}

export interface OfflineEvalTaskDatasetPreHandler {
  type?: DatasetPreHandlerType;
  promptKey?: string;
  promptVersion?: string;
  inputColumn?: string;
  promptID?: string;
  /** Whether the prompt has been deleted */
  isPromptDeleted?: boolean;
}

export interface OfflineEvalTaskInputPreHandler {
  type?: InputPreHandlerType;
  url?: string;
}

export interface OfflineEvalTaskModel {
  source?: OfflineEvalTaskModelSource;
  /** Model being evaluated (if the source is an OpenSource/Ark base model, model information is written here) */
  foundationModel?: model.SftTaskFoundationModel;
  /** The identity of the model being evaluated (in this case the model is an sft product, the identification is an Ark custom_id/model_version, and the foundation model is recorded) */
  identification?: string;
  sftTaskID?: string;
  sftTaskProvider?: model.Provider;
  merlinModelName?: string;
  merlinModelVersion?: string;
  trainingType?: model.SftTaskTrainingType;
  trainingMethod?: model.SftTaskTrainingMethod;
  sftTask?: model.SftTask;
  merlinSeedModelType?: MerlinSeedModelType;
  /** The hdfs address of the model file being evaluated (if the source is seed/sft/OpenSource, the model hdfs address is written here) */
  modelAddress?: string;
  tokenizerAddress?: string;
  networkConfigContext?: string;
  quantConfigContext?: string;
  temperature?: number;
  topP?: number;
  topK?: string;
  maxOutputToken?: string;
  maxContextToken?: string;
  batchSize?: string;
}
/* eslint-enable */
