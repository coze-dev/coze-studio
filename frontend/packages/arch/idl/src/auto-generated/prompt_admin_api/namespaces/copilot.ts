/*
 * Copyright 2025 coze-dev Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
 
// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.
/* eslint-disable */
/* tslint:disable */
// @ts-nocheck

import * as copilot_common from './copilot_common';

export type Int64 = string | number;

export enum BotExeType {
  Create = 1,
  Update = 2,
  Delete = 3,
}

export enum BotSpecies {
  /** Bot type */
  Default = 0,
  Function = 1,
}

export enum BotStatus {
  Using = 0,
  Deleted = 1,
}

export enum BotType {
  /** bot type */
  User = 0,
  Coco = 1,
  GuanFang = 2,
}

export enum ModelCacheType {
  PrefixCache = 1,
}

export enum ModelParamType {
  Float = 1,
  Int = 2,
  Boolean = 3,
  String = 4,
}

export enum ModelProvider {
  GptOpenApi = 1,
  GptEngine = 2,
  MaaS = 3,
  QianFan = 4,
  BytedLLMServer = 5,
}

export enum PromptTemplateType {
  GPT_TOOLS = 0,
  GPT_TOOLS_DATASET = 1,
  GPT_DATASET = 2,
  GPT_NOTHING = 3,
  SEED_MUSIC = 4,
}

export enum RecommendStatus {
  /** personalized recommendation status */
  Enable = 0,
  Disable = 1,
}

export interface BytedLLMServerConf {
  psm?: string;
  idc?: Array<string>;
  cluster?: string;
  /** The configuration value is orca or ultraman or genai. */
  request_type?: string;
  /** Required when using genai */
  chat_template?: string;
  /** Model entry and exit parameters for custom orca frameworks */
  orca_model_param?: OrcaModelParamConf;
}

export interface Capability {
  /** Whether to support function calls */
  function_call?: boolean;
  /** Whether to support Toutiao card types */
  card?: boolean;
  /** Does it support video search? */
  media?: boolean;
  /** execution strategy */
  proxy?: copilot_common.ModelProxy;
  /** Support tools */
  tool?: boolean;
  /** The seed model output is api_name, not plugin + api_name, which will cause the debugger to fail if spliced. This flag prevents splicing */
  fixed_function?: boolean;
  /** For seed_strong_character_with_mem, quoted in bot_prompt_template_jinja */
  profile_memory?: boolean;
  /** Recovery from chat history for bean packet voice link, acting on Seed SC model  */
  resume_segment?: boolean;
  /** Does it support complex parameter calls, such as */
  complex_function_call?: boolean;
  /** Deprecated: Use multimodal_types instead. Whether to support multimodal protocols such as image recognition */
  multi_modal?: boolean;
  /** Does it support json_mode */
  json_mode?: boolean;
  /** Whether to support message naming */
  nameable?: boolean;
  /** Multimodal supported file types, following the MIME standard */
  multimodal_types?: Array<string>;
  /** Whether to support pre-search, aka continuation  */
  pre_query?: boolean;
  /** Whether to support search enhancement, will insert type = search_enhance tool */
  search_enhance?: boolean;
  /** Whether to show thinking */
  cot_display?: boolean;
  /** Supported cache types */
  cache?: Array<ModelCacheType>;
  /** Whether to support continuation */
  prefill_resp?: boolean;
  /** List of wishful cards allowed to be displayed */
  ala_src_allow_list?: Array<string>;
  /** Whether to support batch calls */
  batch?: boolean;
}

export interface GptEngineConf {
  /** Seed runtime */
  runtime?: string;
  /** AB parameter, serialized by json */
  ab_param?: string;
  /** seed app_id */
  app_id?: string;
  /** cluster */
  cluster?: string;
}

export interface GptOpenApiConf {
  /** base request address */
  openai_api_base?: string;
  /** API protocol version */
  openai_api_version?: string;
  /** AZURE / OPEN_AI / AZURE_AD */
  openai_api_type?: string;
}

export interface LegacyFields {
  /** Original model_name value */
  model_name?: Int64;
}

export interface MaasAuthConf {
  ak?: string;
  sk?: string;
  /** When calling Ark, do not specify the large model name, but specify the endpoint. */
  endpoint?: string;
  host?: string;
  region?: string;
}

export interface MaasConf {
  auth?: MaasAuthConf;
  /**  */
  plugins?: Array<string>;
  extra?: Record<string, string>;
  using_stream?: boolean;
  api_version?: string;
  /** Nickname for the Volcano Ark node */
  endpoint_name?: string;
  /** Volcano Ark node creation time */
  endpoint_create_time?: Int64;
}

export interface ModelConf {
  /** Timeout time [ms] */
  timeout?: number;
  /** number of retries */
  retry_times?: number;
  /** Deprecated reply output method */
  print_behavior?: copilot_common.PrintBehavior;
  /** Maas-specific configuration */
  maas?: MaasConf;
  /** Qianfan's unique configuration */
  qianfan?: QianFanConf;
  /** GPT openAPI configuration */
  gpt_openapi?: GptOpenApiConf;
  /** GPT engine configuration */
  gpt_engine?: GptEngineConf;
  /** Byted llm server configuration */
  byted_llm_server?: BytedLLMServerConf;
  /** Platform for providing models, openai maas, etc */
  provider?: ModelProvider;
}

export interface ModelParameter {
  /** Configuration fields, such as max_tokens */
  name?: string;
  /** type */
  type?: ModelParamType;
  /** Is it required? */
  is_required?: boolean;
  /** Numerical type parameters, the minimum value allowed to be set */
  min?: string;
  /** Numerical type parameter, the maximum value allowed to be set */
  max?: string;
  /** Precision of float type parameters */
  precision?: number;
  /** Default values for different styles of parameters */
  default_value?: Record<string, string>;
  /** Enumeration values such as response_format support text, markdown, json */
  options?: Array<string>;
  /** Whether to automatically fix this parameter to the range [min, max], the default is false */
  auto_fix?: boolean;
}

export interface ModelQuota {
  /** Maximum total number of tokens */
  token_limit?: Int64;
  /** Final reply maximum number of tokens */
  token_resp?: Int64;
  /** Prompt system maximum number of tokens */
  token_system?: Int64;
  /** Prompt user to enter maximum number of tokens */
  token_user_in?: Int64;
  /** Prompt tool to enter maximum number of tokens */
  token_tools_in?: Int64;
  /** Prompt tool output maximum number of tokens */
  token_tools_out?: Int64;
  /** Prompt data maximum number of tokens */
  token_data?: Int64;
  /** Prompt history maximum number of tokens */
  token_history?: Int64;
  /** Prompt history maximum number of tokens */
  token_cut_switch?: boolean;
  /** input cost */
  price_in?: number;
  /** output cost */
  price_out?: number;
  /** Bot prompt word configuration token number */
  token_persona?: number;
  /** Capacity for monitoring */
  request_per_minute?: Int64;
  /** Capacity for monitoring */
  token_per_minute?: Int64;
}

export interface OrcaCustomerParam {
  string_lists?: Record<string, Array<string>>;
  int_lists?: Record<string, Array<Int64>>;
  float_lists?: Record<string, Array<number>>;
  string_arrays?: Record<string, Array<Array<string>>>;
}

export interface OrcaModelParamConf {
  /** openai */
  openai_req_key?: string;
  openai_resp_key?: string;
  /** customer */
  in_customer_param?: OrcaCustomerParam;
}

export interface PromptConf {
  /** Template configuration tcc: bot_prompt_sequence */
  sequence?: string;
  /** Template prefix tcc: bot_prompt_template */
  prefix?: string;
  /** Template suffix tcc: bot_prompt_template */
  suffix?: string;
  /** Whether adding personal touch */
  is_sc?: boolean;
  /** Do not enable ReACT (response_format) */
  close_react?: boolean;
  /** User prompt is required */
  is_up_required?: boolean;
}

export interface QianFanAuthConf {
  client_id?: string;
  client_secret?: string;
}

export interface QianFanConf {
  auth?: QianFanAuthConf;
}
/* eslint-enable */
