/*
 * Copyright 2025 coze-dev Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
 
// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.
/* eslint-disable */
/* tslint:disable */
// @ts-nocheck

import * as datasetv2 from './datasetv2';
import * as datasetv2similarity from './datasetv2similarity';

export type Int64 = string | number;

export enum FileFormat {
  JSONL = 1,
  Parquet = 2,
  CSV = 3,
  /** [100, 200] compressed format */
  ZIP = 100,
}

export enum ImportConfirmType {
  NotConfirmed = 0,
  ConfirmedDuplicated = 1,
  ConfirmedNotDuplicated = 2,
}

/** general task state */
export enum JobStatus {
  Undefined = 0,
  /** pending */
  Pending = 1,
  /** Processing */
  Running = 2,
  /** Completed. */
  Completed = 3,
  /** fail */
  Failed = 4,
  /** Cancelled */
  Cancelled = 5,
}

/** generic task type */
export enum JobType {
  ImportFromFile = 1,
  ExportToFile = 2,
  ExportToDataset = 3,
}

export enum SourceType {
  File = 1,
  Dataset = 2,
}

export interface DatasetIODataset {
  spaceID?: string;
  datasetID: string;
  versionID?: string;
  /** Dataset details, returned on the interface, not written */
  dataset?: datasetv2.Dataset;
  /** Version details, returned on the interface, not written */
  version?: datasetv2.DatasetVersion;
}

export interface DatasetIOEndpoint {
  file?: DatasetIOFile;
  dataset?: DatasetIODataset;
}

export interface DatasetIOFile {
  provider: datasetv2.StorageProvider;
  path: string;
  /** Data file format */
  format?: FileFormat;
  /** compressed package format */
  compressFormat?: FileFormat;
  /** Path to folder or zip, data file list, server level settings */
  files?: Array<string>;
  /** The original file name, written by the frontend when the file was created. Empty is consistent with path */
  originalFileName?: string;
}

/** DatasetIOJob dataset import and export task */
export interface DatasetIOJob {
  id: string;
  appID?: number;
  spaceID: string;
  /** When importing and exporting to a file, it is the dataset ID; when transferring between datasets, it is the target dataset ID. */
  datasetID: string;
  jobType: JobType;
  source: DatasetIOEndpoint;
  target: DatasetIOEndpoint;
  /** data field mapping */
  fieldMappings?: Array<FieldMapping>;
  option?: DatasetIOJobOption;
  /** Operational data, [20, 100] */
  status?: JobStatus;
  progress?: DatasetIOJobProgress;
  errors?: Array<datasetv2.ItemErrorGroup>;
  /** general information */
  createdBy?: string;
  createdAt?: string;
  updatedBy?: string;
  updatedAt?: string;
  startedAt?: string;
  endedAt?: string;
}

export interface DatasetIOJobOption {
  /** Overwriting the dataset only takes effect in the import task */
  overwriteDataset?: boolean;
  /** You need to import according to the manually marked taskID result. If it is confirmed that you do not need to import, it will not be imported, and will only take effect in the import task. */
  jobID?: Int64;
}

export interface DatasetIOJobProgress {
  /** total */
  total?: Int64;
  /** Number processed */
  processed?: Int64;
  /** Number of successfully processed */
  added?: Int64;
  /** Number skipped */
  skipped?: Int64;
  /** The next scanned cursor, which takes effect when the data source is a dataset */
  cursor?: string;
  /** subtask
Nullable, indicating the name of the subtask */
  name?: string;
  /** Progress of subtasks */
  subProgresses?: Array<DatasetIOJobProgress>;
}

export interface FieldMapping {
  source: string;
  target: string;
}

export interface ItemDeduplicateJob {
  id: string;
  spaceID: string;
  datasetID: string;
  /** Import the data required for the file */
  jobType?: JobType;
  source?: DatasetIOEndpoint;
  target?: DatasetIOEndpoint;
  /** data field mapping */
  fieldMappings?: Array<FieldMapping>;
  option?: DatasetIOJobOption;
  /** Job information
If status = Completed, it indicates that the processing has been completed */
  status?: JobStatus;
  /** Brief information at the time of the task, redundant storage */
  itemDedupJobBrief?: string;
  /** According to which column deduplicate */
  fieldKey?: string;
  /** deduplicate algorithm */
  similarityAlgorithm?: datasetv2similarity.SimilarityAlgorithm;
  /** threshold */
  threshold?: Int64;
  /** The total data to be processed in the job does not follow the filter criteria */
  jobTotal?: Int64;
  /** The number of confirmed duplicates does not follow the filter criteria */
  confirmedDedupItemsCount?: Int64;
  /** The number of confirmed non-repeating items does not change with the filter criteria */
  confirmedNotDedupItemsCount?: Int64;
  /** Error message, used when JobStatus = Failed */
  error?: string;
  /** Deduplicate list information
Contents of the deduplicate list */
  pairs?: Array<ItemDeduplicatePair>;
  /** The total number of pairs changes with the filter criteria */
  total?: Int64;
  /** general information */
  createdBy?: string;
  createdAt?: string;
  updatedBy?: string;
  updatedAt?: string;
  startedAt?: string;
  endedAt?: string;
}

export interface ItemDeduplicatePair {
  id: string;
  /** primary key */
  uniqKey: string;
  /** newly imported content */
  newItem?: datasetv2.DatasetItem;
  /** Possible duplicate content */
  items?: Array<SuspectedDupItemInfo>;
  /** Whether to confirm */
  importConfirmType?: ImportConfirmType;
  createdBy?: string;
  createdAt?: string;
  updatedBy?: string;
  updatedAt?: string;
}

export interface SuspectedDupItemInfo {
  /** line content */
  item?: datasetv2.DatasetItem;
  /** similarity score */
  score?: Int64;
}
/* eslint-enable */
