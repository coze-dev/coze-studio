/*
 * Copyright 2025 coze-dev Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
 
// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.
/* eslint-disable */
/* tslint:disable */
// @ts-nocheck

import * as datasetv2 from './datasetv2';
import * as datasetv2job from './datasetv2job';

export type Int64 = string | number;

export enum BatchInferDatasetType {
  DatasetV2 = 0,
  HDFS = 1,
  TOS = 2,
}

export enum BatchInferTaskStatus {
  Preparing = 0,
  Launching = 1,
  Inferring = 2,
  Exporting = 3,
  Success = 4,
  Failed = 5,
  Terminated = 6,
}

export enum InputConfigType {
  Raw = 1,
}

export enum MerlinQuotaPoolType {
  /** stable resources */
  Default = 0,
  /** tidal resources */
  Hybrid = 1,
  /** often mixed resources */
  HybridShare = 2,
  /** Third-party resource ali */
  ALI = 3,
  /** Third-party resources hw */
  HW = 4,
  /** hw arm */
  HWARM = 5,
  /** Flexible selling of resources, which may be preempted at any time */
  Spot = 6,
  /** Preemptible stable resource, merlin seed offline reasoning does not allow this resource to be selected */
  Preemptible = 20,
}

export enum MerlinSeedDataProcessType {
  /** normal generation task */
  RayDataset = 1,
  /** multi-round generation task */
  RayDatasetMultiround = 2,
}

export enum MerlinSeedModelType {
  HDFS = 1,
  ModelCard = 2,
}

export enum OutputConfigType {
  Raw = 1,
}

export enum Provider {
  /** GPTOpenAPI = 1//GPT OpenAPI Platformlatform
Volcano Ark */
  Maas = 2,
  /** BotEngine = 3//temporarily specifies seed access from bot_engineseed from bot_engine access
Merlin Platform */
  Merlin = 4,
  /** Merlin-seed platform */
  MerlinSeed = 5,
}

export enum TrainingMethod {
  LoRA = 1,
  Full = 2,
}

export enum TrainingType {
  SftFineTuning = 1,
}

export interface ArkModel {
  foundationModelName?: string;
  foundationModelVersion?: string;
  /** If it is a fine-tuned model, this id is not empty */
  customModelID?: string;
  sftTaskID?: string;
  /** training type */
  trainingType?: TrainingType;
  /** Training method */
  trainingMethod?: TrainingMethod;
}

export interface BatchInferDataset {
  datasetID?: string;
  inputConfig?: InputConfig;
  outputConfig?: OutputConfig;
  /** The default is dataset v2, and hdfs and tos are added in this issue. */
  datasetType?: BatchInferDatasetType;
  /** Dataset HDFS path to be inferred */
  hdfsPath?: string;
  /** The folder path where the picture to be inferred is stored */
  imageHdfsPath?: string;
  /** The hdfs path where the output result is saved */
  outputHdfsPath?: string;
  /** The tos bucket name of the dataset to be inferred */
  tosBucketName?: string;
  /** The TOS object name of the dataset to be inferred */
  tosObjKey?: string;
  /** Output result saved tos bucket name */
  outputTosBucketName?: string;
  /** The name of the tos object saved by the output result */
  outputTosObjKey?: string;
}

export interface BatchInferParam {
  temperature?: number;
  topP?: number;
  topK?: string;
  maxNewToken?: string;
  maxContextToken?: string;
  /** number of inferences */
  inferTimes?: string;
  /** inference batch size */
  batchSize?: string;
}

export interface BatchInferTask {
  /** Not passed on when created */
  id?: Int64;
  name?: string;
  desc?: string;
  batchInferParam?: BatchInferParam;
  provider?: Provider;
  providerInfo?: ProviderInfo;
  providerTaskID?: string;
  batchInferDatasets?: Array<BatchInferDataset>;
  ckptConfigs?: Record<string, CkptConfig>;
  status?: BatchInferTaskStatus;
  errCode?: string;
  errMsg?: string;
  ckptExecRes?: CkptExecResult;
  /** Fornax space ID */
  spaceID?: string;
  /** creator ID */
  createdBy?: string;
  /** Creation time, seconds */
  createdAt?: string;
  /** Updater ID */
  updatedBy?: string;
  /** Update time in seconds */
  updatedAt?: string;
}

export interface CkptConfig {
  name?: string;
  maxRetryTime?: string;
  retryIntervalMilliSecond?: string;
  /** The way the retry interval changes, supporting fixed intervals and gradual changes over time */
  retryIntervalChangeType?: string;
  /** For every x retries, the retry interval changes */
  retryIntervalChangeTimes?: string;
  /** The step size of each retry interval, in ms, can be negative */
  retryIntervalChangeStep?: string;
  customConfigs?: Record<string, string>;
  /** Time interval to trigger the next checkpoint in ms */
  triggerNextCkptIntervalMilliSecond?: string;
}

export interface CkptExecResult {
  /** Upload dataset to HDFS [1, 10]
Address where the dataset is uploaded to HDFS */
  datasetHdfsAddress?: string;
  /** Upload progress, same length as batchInferDatasets */
  datasetUploadProgresses?: Array<InferUploadProgress>;
  /** Incoming data column names for offline inference tasks */
  inferTaskColumnName?: string;
  /** The column name where the item id is located */
  itemIDColumnName?: string;
  /** Column name where dataset id is located */
  datasetIDColumnName?: string;
  /** Upload the dataset to the bucket of tos */
  datasetTosBucket?: string;
  /** Dataset object key uploaded to tos */
  datasetTosObjectKey?: string;
  /** Create reasoning tasks [10, 20]
The merlin seed offline inference task is actually outsourced in the merlin task use case, record the merlin task use case id here */
  merlinJobID?: string;
  /** Merlin seed offline inference task link */
  merlinDataProcessTaskUrl?: string;
  /** Third-party platform task link */
  providerTaskUrl?: string;
  /** Check inference task status [20, 30]
Merlin inference task status */
  merlinDataProcessInstanceStatusGroup?: string;
  /** Merlin inference task status details */
  merlinDataProcessInstanceStatus?: string;
  /** Merlin task instance terminated */
  merlinJobTerminated?: boolean;
  /** Merlin task instance status */
  merlinJobStatus?: string;
  /** Merlin task instance error message */
  merlinJobErrMsg?: string;
  /** There are error messages reported by the merlin task instance */
  merlinJobUploadedErrMsg?: string;
  /** Ark mission status */
  arkJobStatus?: string;
  /** Ark mission status description */
  arkJobDetail?: string;
  /** Ark mission status update time */
  arkJobStatusUpdateTimeMs?: Int64;
  /** Derived inference results [30, 40]
Column names for inference output */
  inferResultColumnName?: string;
  /** The hdfs address where the inference result is saved, possibly a folder */
  inferResultHdfsAddress?: string;
  /** Is the result exported? */
  resultExported?: boolean;
  /** Inference result export progress */
  inferExportProgress?: InferExportProgress;
}

export interface InferExportProgress {
  /** Storage platform for inference results */
  provider?: datasetv2.StorageProvider;
  /** The file format of the inference result. If the path of the result is a folder, then only export all files in this format in this folder */
  fileFormat?: datasetv2job.FileFormat;
  /** The address of the export result, which can be a folder. */
  path?: string;
  /** Sub-progress (progress of all resulting files) */
  subProgresses?: Array<InferExportProgress>;
  /** progress information
total number of rows */
  total?: Int64;
  /** Number of rows processed */
  processed?: Int64;
  /** Add the number of successful rows */
  added?: Int64;
  /** run log
Error message, this field is not available in the child progress */
  errors?: Array<datasetv2.ItemErrorGroup>;
}

export interface InferUploadProgress {
  /** Storage platform to be uploaded to */
  provider?: datasetv2.StorageProvider;
  /** File format to be uploaded */
  fileFormat?: datasetv2job.FileFormat;
  /** Uploaded address */
  path?: string;
  /** Sub-progress (progress of all uploaded files) */
  subProgresses?: Array<InferExportProgress>;
  /** The dataset ID to be uploaded, which is not available in the child progress */
  datasetID?: Int64;
  /** The cursor uploaded by the current dataset, this field is not available in the child progress */
  cursor?: string;
  /** progress information
total number of rows */
  total?: Int64;
  /** Number of rows processed */
  processed?: Int64;
}

export interface InputConfig {
  type?: InputConfigType;
  /** Dataset column name as input */
  rawInput?: string;
  /** Uniquely identifying column names for each row of data */
  itemID?: string;
}

export interface MerlinModel {
  /** Record some extra information, such as whether it is a pedestal model or a trained model. If it is a trained model, then you also need to record the id of the training task.
Model file save address */
  hdfsPath?: string;
  /** pedestal model name */
  foundationModelName?: string;
  /** 3: optional string foundationModelFamily//base model familyal model family
4: optional string foundationModelVendor//base model manufacturerodel manufacturer
5: optional string foundationModelDisplayName//base model display name model display name
6: optional i64 foundationModelVersionUpdateTimeInMs//base model version update time version update time
Training task id. When the training task is non-zero, it means that the model used for this batch inference is the product of training */
  sftTaskID?: string;
  /** The name of the training product (this requires that the product has been exported to Merlin's model repository, so this name is the name of a model repository in Merlin) */
  merlinModelName?: string;
  /** A version of one of Merlin's model repositories */
  merlinModelVersion?: string;
  /** training type */
  trainingType?: TrainingType;
  /** Training method */
  trainingMethod?: TrainingMethod;
}

export interface MerlinResource {
  type?: MerlinQuotaPoolType;
  /** User group id, only 1 is supported for the time being. */
  groupIDs?: Array<string>;
  /** cluster id */
  clusterID?: string;
  /** Whether to use available resources */
  preemptible?: boolean;
  /** Role configuration, only 1 is supported for the time being. */
  roles?: Array<MerlinResourceRole>;
  /** Key is the user group id and val is the user group name */
  groupNames?: Record<Int64, string>;
  /** cluster name */
  clusterName?: string;
}

export interface MerlinResourceRole {
  /** Number of instances, required 1 */
  num?: number;
  /** Virtual GPU model */
  gpuv?: string;
  /** Number of GPUs */
  gpu?: number;
  /** CPU number */
  cpu?: number;
  /** Memory size, in MB */
  memory?: number;
}

export interface MerlinSeedModel {
  merlinSeedModelType?: MerlinSeedModelType;
  hdfsAddress?: string;
  modelCardID?: string;
  modelCardName?: string;
  modelParamConfigType?: string;
  tokenizerAddress?: string;
  networkConfig?: string;
  quantConfig?: string;
}

export interface ModelCard {
  id?: string;
  name?: string;
}

export interface OutputConfig {
  type?: OutputConfigType;
  /** The output will be saved in this dataset column name */
  rawOutput?: string;
  /** The full output will be saved in this dataset column name (currently only ARK/open source models/trained open source models are supported). */
  completeOutput?: string;
}

export interface ProviderInfo {
  provider?: Provider;
  merlinSeedModel?: MerlinSeedModel;
  merlinResource?: MerlinResource;
  merlinCustomEnvs?: Record<string, string>;
  merlinSeedDataProcessType?: MerlinSeedDataProcessType;
  /** open source model */
  merlinModel?: MerlinModel;
  /** Ark model */
  arkModel?: ArkModel;
  /** Ark project name */
  arkProjectName?: string;
}
/* eslint-enable */
